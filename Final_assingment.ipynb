{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final_assingment.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hYwIsQhf_Nm",
        "colab_type": "code",
        "outputId": "20aab1c0-4258-49e7-c477-376d2ab81401",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "\n",
        "#  importing all the libraries required for the experiment\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "import datetime\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from collections import Counter\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.util import ngrams\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "pd.set_option('max_colwidth',400)"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFLHMFCbgNA7",
        "colab_type": "code",
        "outputId": "9e210f3b-f74a-453f-e5e8-1150fb145c2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        }
      },
      "source": [
        "\n",
        "#  reading the dataset file from the content folder\n",
        "train = pd.read_csv('/content/train.tsv.txt', delimiter='\\t', usecols = ['SentenceId','Phrase','Sentiment'])\n",
        "pd.set_option('display.max_colwidth', -1)\n",
        "# displaying top 10 records of the dataset with all the headers\n",
        "train.head(10)\n"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SentenceId</th>\n",
              "      <th>Phrase</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>A series of escapades demonstrating the adage that what is good for the goose is also good for the gander , some of which occasionally amuses but none of which amounts to much of a story .</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>A series of escapades demonstrating the adage that what is good for the goose</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>A series</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>series</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1</td>\n",
              "      <td>of escapades demonstrating the adage that what is good for the goose</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "      <td>of</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1</td>\n",
              "      <td>escapades demonstrating the adage that what is good for the goose</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1</td>\n",
              "      <td>escapades</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1</td>\n",
              "      <td>demonstrating the adage that what is good for the goose</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   SentenceId  ... Sentiment\n",
              "0  1           ...  1       \n",
              "1  1           ...  2       \n",
              "2  1           ...  2       \n",
              "3  1           ...  2       \n",
              "4  1           ...  2       \n",
              "5  1           ...  2       \n",
              "6  1           ...  2       \n",
              "7  1           ...  2       \n",
              "8  1           ...  2       \n",
              "9  1           ...  2       \n",
              "\n",
              "[10 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tReLksL1hV83",
        "colab_type": "code",
        "outputId": "75f8f378-f672-4daa-d696-954d6dca8ada",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "# printing the sentiment counts for each sentiment in the dataset\n",
        "train['Sentiment'].value_counts()"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2    79582\n",
              "3    32927\n",
              "1    27273\n",
              "4    9206 \n",
              "0    7072 \n",
              "Name: Sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xx4N5R9oi_Mq",
        "colab_type": "code",
        "outputId": "721e1af0-1c08-4e99-b38d-84ece3c5bd6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# importing libraries for the pre processing of the data\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import FreqDist\n",
        "from nltk.stem import SnowballStemmer,WordNetLemmatizer,PorterStemmer,LancasterStemmer\n",
        "from string import punctuation\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "stemmer=LancasterStemmer()\n",
        "lemma=WordNetLemmatizer()\n",
        "stopwords_en = stopwords.words(\"english\")\n",
        "punctuations=\"?:!.,;'\\\"-()\"\n",
        "remove_stopwords = False\n",
        "useStemming = True\n",
        "useLemma = True\n",
        "removePuncs = True"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wz-VxcwJjCDG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#  creating a clean review column which is done after removeing stop words and lower case all the words.\n",
        "#  wordnet lemmatizer is used to lemmatize the words.\n",
        "def final_review(review_col):\n",
        "    review_corpus=[]\n",
        "    for i in range(0,len(review_col)):\n",
        "      review=str(review_col[i])\n",
        "      review=re.sub('[^a-zA-Z]',' ',review)\n",
        "        \n",
        "      if useStemming:\n",
        "        review = stemmer.stem(review)\n",
        "      if useLemma:\n",
        "         review=[lemma.lemmatize(w) for w in word_tokenize(str(review).lower())]\n",
        "      review=' '.join(review)\n",
        "      review_corpus.append(review)\n",
        "    return review_corpus\n",
        "\n",
        "       \n",
        "        # review=re.sub('[^a-zA-Z]',' ',review)\n",
        "        # review = stemmer.stem(review)\n",
        "       \n",
        "        \n",
        "       \n",
        "    \n",
        "\n",
        "   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUEjGA-pjEqs",
        "colab_type": "code",
        "outputId": "a00972df-6e89-4ecd-cba8-c105b725a85d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        }
      },
      "source": [
        " \n",
        "# displaying the result of the clean review after the preprocessing\n",
        "train['final_review']=final_review(train.Phrase.values)\n",
        "train.head(5)"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SentenceId</th>\n",
              "      <th>Phrase</th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>final_review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>A series of escapades demonstrating the adage that what is good for the goose is also good for the gander , some of which occasionally amuses but none of which amounts to much of a story .</td>\n",
              "      <td>1</td>\n",
              "      <td>a series of escapade demonstrating the adage that what is good for the goose is also good for the gander some of which occasionally amuses but none of which amount to much of a story</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>A series of escapades demonstrating the adage that what is good for the goose</td>\n",
              "      <td>2</td>\n",
              "      <td>a series of escapade demonstrating the adage that what is good for the goose</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>A series</td>\n",
              "      <td>2</td>\n",
              "      <td>a series</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>2</td>\n",
              "      <td>a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>series</td>\n",
              "      <td>2</td>\n",
              "      <td>sery</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   SentenceId  ...                                                                                                                                                                            final_review\n",
              "0  1           ...  a series of escapade demonstrating the adage that what is good for the goose is also good for the gander some of which occasionally amuses but none of which amount to much of a story\n",
              "1  1           ...  a series of escapade demonstrating the adage that what is good for the goose                                                                                                          \n",
              "2  1           ...  a series                                                                                                                                                                              \n",
              "3  1           ...  a                                                                                                                                                                                     \n",
              "4  1           ...  sery                                                                                                                                                                                  \n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PG23Yn5qnkKl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = TweetTokenizer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ia_hDT1UnoMw",
        "colab_type": "code",
        "outputId": "65de1987-b783-43e1-c432-59d76c0a9b31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "# word tokenizing the data from the clean phrases obtained after the preprocessing\n",
        "vectorizer = TfidfVectorizer(ngram_range=(1, 2), tokenizer=tokenizer.tokenize)\n",
        "full_text = list(train['final_review'].values) \n",
        "vectorizer.fit(full_text)\n",
        "upsampled_vectorized_data = vectorizer.transform(train['final_review'])\n"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:507: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNRdilFooAMq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#  storing the sentiment value in the Y column\n",
        "y = train['Sentiment']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZqQ4BcfZoG7v",
        "colab_type": "code",
        "outputId": "8cde62f8-2057-4d8e-af07-67a939a486f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        }
      },
      "source": [
        "#  since the data is a multi class , we turn the sentiment into categorical form for easy processing and classfication\n",
        "from keras.utils import to_categorical\n",
        "X = train['final_review']\n",
        "\n",
        "Y = to_categorical(train['Sentiment'].values)\n",
        "print(Y)"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. 1. 0.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bX2UGM6SoQNB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#  splitting the train file into train and test with ration of 70 and 30\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=123)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8g56qBhoa3x",
        "colab_type": "code",
        "outputId": "6eef0f7a-5ae7-4815-8db5-e1f8a3b1c81a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "#  printing the shape of the X and Y column of the train set\n",
        "print(type(X_train))\n",
        "print(X_train.shape,Y_train.shape)\n",
        "print(X_test.shape,Y_test.shape)\n"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.series.Series'>\n",
            "(109242,) (109242, 5)\n",
            "(46818,) (46818, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zHgbv68ohdn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMtq_WpXojvV",
        "colab_type": "code",
        "outputId": "82a49486-6a1a-4301-a32e-2bd0c2c95a74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#  word tokenizing the train set and generating the frequency distribution\n",
        "all_words=' '.join(X_train)\n",
        "all_words=word_tokenize(all_words)\n",
        "#print(all_words)\n",
        "fre_dist=FreqDist(all_words)\n",
        "\n",
        "total_unique_word=len(fre_dist)\n",
        "total_unique_word\n",
        "#X_train.head()"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17715"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hs_lY1KXomLw",
        "colab_type": "code",
        "outputId": "3d860d6a-c94f-4578-bb90-ceeba94ae0e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#  max length for the embbeder is set after tokenizing\n",
        "r_len=[]\n",
        "for text in X_train:\n",
        "    word=word_tokenize(text)\n",
        "  #  print(text)\n",
        "    l=len(word)\n",
        "    r_len.append(l)\n",
        "    \n",
        "MAX_word_len=np.max(r_len)\n",
        "MAX_word_len"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "48"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTcTvV0oooAa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#  setting the maximum features obtained from tokenizing and TFIDF and setting teh epocha and batch size for the model input\n",
        "max_features = total_unique_word\n",
        "max_words = MAX_word_len\n",
        "batch_size = 128\n",
        "epochs = 10\n",
        "num_classes=5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQH2QwxFoqOW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from tensorflow.python.keras.models import Sequential\n",
        "from tensorflow.python.keras.layers import Dense, GRU, Embedding\n",
        "from tensorflow.python.keras.optimizers import Adam\n",
        "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.python.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blHhvRoaos02",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#  tokenizing text to sequences for the test and train set\n",
        "tokenizer = Tokenizer(num_words=max_features)\n",
        "tokenizer.fit_on_texts(X)\n",
        "X_train = tokenizer.texts_to_sequences(X_train)\n",
        "# X_val = tokenizer.texts_to_sequences(X_val)\n",
        "\n",
        "X_test = tokenizer.texts_to_sequences(X_test)\n",
        "#X_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ylK5hXBoz5r",
        "colab_type": "code",
        "outputId": "a0227f31-a80c-427b-a591-de613702cc2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        }
      },
      "source": [
        "from keras.preprocessing import sequence,text\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.models import Sequential\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "X_train = sequence.pad_sequences(X_train, maxlen=max_words)\n",
        "# X_val = sequence.pad_sequences(X_val, maxlen=max_words)\n",
        "X_test = sequence.pad_sequences(X_test, maxlen=max_words)\n",
        "#print(X_train.shape,X_val.shape)\n",
        "X_test"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[    0,     0,     0, ...,     0,     0, 14660],\n",
              "       [    0,     0,     0, ...,     8,     1,  2759],\n",
              "       [    0,     0,     0, ...,   516,     1,  1198],\n",
              "       ...,\n",
              "       [    0,     0,     0, ...,     3,   362,  5535],\n",
              "       [    0,     0,     0, ...,     1,   795,   152],\n",
              "       [    0,     0,     0, ...,     0,   189,   908]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLMvWwHSo9XV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Input, Dense, Embedding, Flatten\n",
        "from keras.layers import SpatialDropout1D\n",
        "from keras.layers.convolutional import Conv1D, MaxPooling1D\n",
        "from keras.models import Sequential"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLEM13_Lo_bU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#  building the model with all teh layers used for efficent classfication\n",
        "cnn_model = Sequential()\n",
        "\n",
        "# Input / Embdedding\n",
        "cnn_model.add(Embedding(max_features, 150, input_length=max_words))\n",
        "\n",
        "# CNN\n",
        "cnn_model.add(SpatialDropout1D(0.2))\n",
        "\n",
        "cnn_model.add(Conv1D(32, kernel_size=3, padding='same', activation='relu'))\n",
        "cnn_model.add(MaxPooling1D(pool_size=2))\n",
        "\n",
        "cnn_model.add(Conv1D(64, kernel_size=3, padding='same', activation='relu'))\n",
        "cnn_model.add(MaxPooling1D(pool_size=2))\n",
        "\n",
        "cnn_model.add(Flatten())\n",
        "\n",
        "# Output layer\n",
        "cnn_model.add(Dense(5, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KiXMuii1pWEL",
        "colab_type": "code",
        "outputId": "850e3901-70cd-4d8d-ef6e-6387bec2f967",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 665
        }
      },
      "source": [
        "#  passing the training set to the model with loss and accuracy metrics\n",
        "cnn_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "history = cnn_model.fit(X_train, Y_train,validation_data= (X_test, Y_test) ,epochs=epochs, batch_size=batch_size, verbose=1)\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 109242 samples, validate on 46818 samples\n",
            "Epoch 1/10\n",
            "109242/109242 [==============================] - 7s 66us/step - loss: 1.0330 - acc: 0.5870 - val_loss: 0.8861 - val_acc: 0.6400\n",
            "Epoch 2/10\n",
            "109242/109242 [==============================] - 6s 59us/step - loss: 0.7918 - acc: 0.6767 - val_loss: 0.8397 - val_acc: 0.6590\n",
            "Epoch 3/10\n",
            "109242/109242 [==============================] - 6s 58us/step - loss: 0.6977 - acc: 0.7144 - val_loss: 0.8459 - val_acc: 0.6609\n",
            "Epoch 4/10\n",
            "109242/109242 [==============================] - 6s 59us/step - loss: 0.6311 - acc: 0.7385 - val_loss: 0.8705 - val_acc: 0.6569\n",
            "Epoch 5/10\n",
            "109242/109242 [==============================] - 6s 59us/step - loss: 0.5796 - acc: 0.7587 - val_loss: 0.9267 - val_acc: 0.6547\n",
            "Epoch 6/10\n",
            "109242/109242 [==============================] - 6s 59us/step - loss: 0.5349 - acc: 0.7761 - val_loss: 0.9471 - val_acc: 0.6525\n",
            "Epoch 7/10\n",
            "109242/109242 [==============================] - 6s 59us/step - loss: 0.4970 - acc: 0.7920 - val_loss: 1.0066 - val_acc: 0.6411\n",
            "Epoch 8/10\n",
            "109242/109242 [==============================] - 6s 59us/step - loss: 0.4657 - acc: 0.8051 - val_loss: 1.0620 - val_acc: 0.6430\n",
            "Epoch 9/10\n",
            "109242/109242 [==============================] - 6s 59us/step - loss: 0.4384 - acc: 0.8164 - val_loss: 1.1039 - val_acc: 0.6391\n",
            "Epoch 10/10\n",
            "109242/109242 [==============================] - 6s 58us/step - loss: 0.4139 - acc: 0.8250 - val_loss: 1.1593 - val_acc: 0.6355\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nY/zc/wdFct6PR1+qnQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGgkPcSbuRwf",
        "colab_type": "code",
        "outputId": "a0c07ac2-9574-4034-f13e-75dd7e0c5542",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHOHnH3Sud_a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# saving the state of the model for future use\n",
        "cnn_model.save(\"1105500_1Dcnn.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSCxhMNQuiCW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model\n",
        "model = load_model('1105500_1Dcnn.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AiebGVx33fX5",
        "colab_type": "code",
        "outputId": "666f73e7-b397-43a1-e53f-93d1211d4d47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        }
      },
      "source": [
        "# testing the model and displaying the precision, recall and f1 score of the model\n",
        "from sklearn.metrics import classification_report\n",
        "predection=cnn_model.predict_classes(X_test,verbose=1)\n",
        "Y_test=np.argmax(Y_test, axis=1)\n",
        "print(classification_report(Y_test, predection, digits=5))"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "46818/46818 [==============================] - 2s 49us/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0    0.45547   0.42417   0.43926      2110\n",
            "           1    0.52164   0.51318   0.51737      8081\n",
            "           2    0.73913   0.75548   0.74721     23920\n",
            "           3    0.53829   0.54154   0.53991      9929\n",
            "           4    0.51278   0.45500   0.48217      2778\n",
            "\n",
            "    accuracy                        0.63552     46818\n",
            "   macro avg    0.55346   0.53787   0.54519     46818\n",
            "weighted avg    0.63278   0.63552   0.63397     46818\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KmX6-1ZB324U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}