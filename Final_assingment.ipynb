{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final_assingment.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hYwIsQhf_Nm",
        "colab_type": "code",
        "outputId": "efe47f2b-34f7-4967-f94b-08acd1c3d04b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "\n",
        "#  importing all the libraries required for the experiment\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "import datetime\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from collections import Counter\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.util import ngrams\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "pd.set_option('max_colwidth',400)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFLHMFCbgNA7",
        "colab_type": "code",
        "outputId": "32483e41-0c3b-45ca-cabf-2afcd5b39a20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        }
      },
      "source": [
        "\n",
        "#  reading the dataset file from the content folder\n",
        "train = pd.read_csv('/content/train.tsv.txt', delimiter='\\t', usecols = ['SentenceId','Phrase','Sentiment'])\n",
        "pd.set_option('display.max_colwidth', -1)\n",
        "# displaying top 10 records of the dataset with all the headers\n",
        "train.head(10)\n"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SentenceId</th>\n",
              "      <th>Phrase</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>A series of escapades demonstrating the adage that what is good for the goose is also good for the gander , some of which occasionally amuses but none of which amounts to much of a story .</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>A series of escapades demonstrating the adage that what is good for the goose</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>A series</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>series</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1</td>\n",
              "      <td>of escapades demonstrating the adage that what is good for the goose</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "      <td>of</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1</td>\n",
              "      <td>escapades demonstrating the adage that what is good for the goose</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1</td>\n",
              "      <td>escapades</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1</td>\n",
              "      <td>demonstrating the adage that what is good for the goose</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   SentenceId  ... Sentiment\n",
              "0  1           ...  1       \n",
              "1  1           ...  2       \n",
              "2  1           ...  2       \n",
              "3  1           ...  2       \n",
              "4  1           ...  2       \n",
              "5  1           ...  2       \n",
              "6  1           ...  2       \n",
              "7  1           ...  2       \n",
              "8  1           ...  2       \n",
              "9  1           ...  2       \n",
              "\n",
              "[10 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tReLksL1hV83",
        "colab_type": "code",
        "outputId": "c6ba69cd-1597-4795-c3b5-7816f9774fed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "# printing the sentiment counts for each sentiment in the dataset\n",
        "train['Sentiment'].value_counts()"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2    79582\n",
              "3    32927\n",
              "1    27273\n",
              "4    9206 \n",
              "0    7072 \n",
              "Name: Sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xx4N5R9oi_Mq",
        "colab_type": "code",
        "outputId": "8730566e-7a85-4c27-a338-19231a450c7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# importing libraries for the pre processing of the data\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import FreqDist\n",
        "from nltk.stem import SnowballStemmer,WordNetLemmatizer,PorterStemmer,LancasterStemmer\n",
        "from string import punctuation\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "stemmer=LancasterStemmer()\n",
        "lemma=WordNetLemmatizer()\n",
        "stopwords_en = stopwords.words(\"english\")\n",
        "punctuations=\"?:!.,;'\\\"-()\"\n",
        "remove_stopwords = False\n",
        "useStemming = True\n",
        "useLemma = True\n",
        "removePuncs = True"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wz-VxcwJjCDG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#  creating a clean review column which is done after removeing stop words and lower case all the words.\n",
        "#  wordnet lemmatizer is used to lemmatize the words.\n",
        "def final_review(review_col):\n",
        "    review_corpus=[]\n",
        "    for i in range(0,len(review_col)):\n",
        "      review=str(review_col[i])\n",
        "      review=re.sub('[^a-zA-Z]',' ',review)\n",
        "        \n",
        "      if useStemming:\n",
        "        review = stemmer.stem(review)\n",
        "      if useLemma:\n",
        "         review=[lemma.lemmatize(w) for w in word_tokenize(str(review).lower())]\n",
        "      review=' '.join(review)\n",
        "      review_corpus.append(review)\n",
        "    return review_corpus\n",
        "\n",
        "       \n",
        "        # review=re.sub('[^a-zA-Z]',' ',review)\n",
        "        # review = stemmer.stem(review)\n",
        "       \n",
        "        \n",
        "       \n",
        "    \n",
        "\n",
        "   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUEjGA-pjEqs",
        "colab_type": "code",
        "outputId": "df55b9a6-1633-45bc-da08-5e799b214e70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        }
      },
      "source": [
        " \n",
        "# displaying the result of the clean review after the preprocessing\n",
        "train['final_review']=final_review(train.Phrase.values)\n",
        "train.head(5)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SentenceId</th>\n",
              "      <th>Phrase</th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>final_review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>A series of escapades demonstrating the adage that what is good for the goose is also good for the gander , some of which occasionally amuses but none of which amounts to much of a story .</td>\n",
              "      <td>1</td>\n",
              "      <td>a series of escapade demonstrating the adage that what is good for the goose is also good for the gander some of which occasionally amuses but none of which amount to much of a story</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>A series of escapades demonstrating the adage that what is good for the goose</td>\n",
              "      <td>2</td>\n",
              "      <td>a series of escapade demonstrating the adage that what is good for the goose</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>A series</td>\n",
              "      <td>2</td>\n",
              "      <td>a series</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>2</td>\n",
              "      <td>a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>series</td>\n",
              "      <td>2</td>\n",
              "      <td>sery</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   SentenceId  ...                                                                                                                                                                            final_review\n",
              "0  1           ...  a series of escapade demonstrating the adage that what is good for the goose is also good for the gander some of which occasionally amuses but none of which amount to much of a story\n",
              "1  1           ...  a series of escapade demonstrating the adage that what is good for the goose                                                                                                          \n",
              "2  1           ...  a series                                                                                                                                                                              \n",
              "3  1           ...  a                                                                                                                                                                                     \n",
              "4  1           ...  sery                                                                                                                                                                                  \n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PG23Yn5qnkKl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = TweetTokenizer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ia_hDT1UnoMw",
        "colab_type": "code",
        "outputId": "91327e18-6833-48de-b632-10153bde2c08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "# word tokenizing the data from the clean phrases obtained after the preprocessing\n",
        "vectorizer = TfidfVectorizer(ngram_range=(1, 2), tokenizer=tokenizer.tokenize)\n",
        "full_text = list(train['final_review'].values) \n",
        "vectorizer.fit(full_text)\n",
        "upsampled_vectorized_data = vectorizer.transform(train['final_review'])\n"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:507: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNRdilFooAMq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#  storing the sentiment value in the Y column\n",
        "y = train['Sentiment']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZqQ4BcfZoG7v",
        "colab_type": "code",
        "outputId": "867d36f6-e5f8-4d1b-9d8a-0af61663371d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        }
      },
      "source": [
        "#  since the data is a multi class , we turn the sentiment into categorical form for easy processing and classfication\n",
        "from keras.utils import to_categorical\n",
        "X = train['final_review']\n",
        "\n",
        "Y = to_categorical(train['Sentiment'].values)\n",
        "print(Y)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. 1. 0.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bX2UGM6SoQNB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#  splitting the train file into train and test with ration of 70 and 30\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=123)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8g56qBhoa3x",
        "colab_type": "code",
        "outputId": "133789b2-9e28-4c59-ce0c-fc9f9434ebfb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "#  printing the shape of the X and Y column of the train set\n",
        "print(type(X_train))\n",
        "print(X_train.shape,Y_train.shape)\n",
        "print(X_test.shape,Y_test.shape)\n"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.series.Series'>\n",
            "(109242,) (109242, 5)\n",
            "(46818,) (46818, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zHgbv68ohdn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMtq_WpXojvV",
        "colab_type": "code",
        "outputId": "bbed7fed-3822-49f2-f894-7b760198c11d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#  word tokenizing the train set and generating the frequency distribution\n",
        "all_words=' '.join(X_train)\n",
        "all_words=word_tokenize(all_words)\n",
        "#print(all_words)\n",
        "fre_dist=FreqDist(all_words)\n",
        "\n",
        "total_unique_word=len(fre_dist)\n",
        "total_unique_word\n",
        "#X_train.head()"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17715"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hs_lY1KXomLw",
        "colab_type": "code",
        "outputId": "35e1d557-bd8d-4971-a91e-7c1bad899452",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#  max length for the embbeder is set after tokenizing\n",
        "r_len=[]\n",
        "for text in X_train:\n",
        "    word=word_tokenize(text)\n",
        "  #  print(text)\n",
        "    l=len(word)\n",
        "    r_len.append(l)\n",
        "    \n",
        "MAX_word_len=np.max(r_len)\n",
        "MAX_word_len"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "48"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTcTvV0oooAa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#  setting the maximum features obtained from tokenizing and TFIDF and setting teh epocha and batch size for the model input\n",
        "max_features = total_unique_word\n",
        "max_words = MAX_word_len\n",
        "batch_size = 128\n",
        "epochs = 10\n",
        "num_classes=5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQH2QwxFoqOW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from tensorflow.python.keras.models import Sequential\n",
        "from tensorflow.python.keras.layers import Dense, GRU, Embedding\n",
        "from tensorflow.python.keras.optimizers import Adam\n",
        "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.python.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blHhvRoaos02",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#  tokenizing text to sequences for the test and train set\n",
        "tokenizer = Tokenizer(num_words=max_features)\n",
        "tokenizer.fit_on_texts(X)\n",
        "X_train = tokenizer.texts_to_sequences(X_train)\n",
        "# X_val = tokenizer.texts_to_sequences(X_val)\n",
        "\n",
        "X_test = tokenizer.texts_to_sequences(X_test)\n",
        "#X_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ylK5hXBoz5r",
        "colab_type": "code",
        "outputId": "62560282-7a78-4538-edc9-40a75010524a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        }
      },
      "source": [
        "from keras.preprocessing import sequence,text\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.models import Sequential\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "X_train = sequence.pad_sequences(X_train, maxlen=max_words)\n",
        "# X_val = sequence.pad_sequences(X_val, maxlen=max_words)\n",
        "X_test = sequence.pad_sequences(X_test, maxlen=max_words)\n",
        "#print(X_train.shape,X_val.shape)\n",
        "X_test"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[    0,     0,     0, ...,     0,     0, 14660],\n",
              "       [    0,     0,     0, ...,     8,     1,  2759],\n",
              "       [    0,     0,     0, ...,   516,     1,  1198],\n",
              "       ...,\n",
              "       [    0,     0,     0, ...,     3,   362,  5535],\n",
              "       [    0,     0,     0, ...,     1,   795,   152],\n",
              "       [    0,     0,     0, ...,     0,   189,   908]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLMvWwHSo9XV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Input, Dense, Embedding, Flatten\n",
        "from keras.layers import SpatialDropout1D\n",
        "from keras.layers.convolutional import Conv1D, MaxPooling1D\n",
        "from keras.models import Sequential"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLEM13_Lo_bU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#  building the model with all teh layers used for efficent classfication\n",
        "cnn_model = Sequential()\n",
        "\n",
        "# Input / Embdedding\n",
        "cnn_model.add(Embedding(max_features, 150, input_length=max_words))\n",
        "\n",
        "# CNN\n",
        "cnn_model.add(SpatialDropout1D(0.2))\n",
        "\n",
        "cnn_model.add(Conv1D(32, kernel_size=3, padding='same', activation='relu'))\n",
        "cnn_model.add(MaxPooling1D(pool_size=2))\n",
        "\n",
        "cnn_model.add(Conv1D(64, kernel_size=3, padding='same', activation='relu'))\n",
        "cnn_model.add(MaxPooling1D(pool_size=2))\n",
        "\n",
        "cnn_model.add(Flatten())\n",
        "\n",
        "# Output layer\n",
        "cnn_model.add(Dense(5, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KiXMuii1pWEL",
        "colab_type": "code",
        "outputId": "f0f6af17-4645-4ac7-a152-9f78b873a9ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 665
        }
      },
      "source": [
        "#  passing the training set to the model with loss and accuracy metrics\n",
        "cnn_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "history = cnn_model.fit(X_train, Y_train,validation_data= (X_test, Y_test) ,epochs=epochs, batch_size=batch_size, verbose=1)\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 109242 samples, validate on 46818 samples\n",
            "Epoch 1/10\n",
            "109242/109242 [==============================] - 7s 64us/step - loss: 1.0127 - acc: 0.5951 - val_loss: 0.8771 - val_acc: 0.6470\n",
            "Epoch 2/10\n",
            "109242/109242 [==============================] - 6s 59us/step - loss: 0.7863 - acc: 0.6773 - val_loss: 0.8419 - val_acc: 0.6588\n",
            "Epoch 3/10\n",
            "109242/109242 [==============================] - 6s 59us/step - loss: 0.6947 - acc: 0.7133 - val_loss: 0.8464 - val_acc: 0.6593\n",
            "Epoch 4/10\n",
            "109242/109242 [==============================] - 6s 59us/step - loss: 0.6258 - acc: 0.7399 - val_loss: 0.8743 - val_acc: 0.6575\n",
            "Epoch 5/10\n",
            "109242/109242 [==============================] - 6s 58us/step - loss: 0.5728 - acc: 0.7596 - val_loss: 0.9170 - val_acc: 0.6510\n",
            "Epoch 6/10\n",
            "109242/109242 [==============================] - 7s 61us/step - loss: 0.5319 - acc: 0.7772 - val_loss: 0.9529 - val_acc: 0.6485\n",
            "Epoch 7/10\n",
            "109242/109242 [==============================] - 7s 60us/step - loss: 0.4944 - acc: 0.7934 - val_loss: 1.0167 - val_acc: 0.6402\n",
            "Epoch 8/10\n",
            "109242/109242 [==============================] - 6s 59us/step - loss: 0.4612 - acc: 0.8048 - val_loss: 1.0860 - val_acc: 0.6459\n",
            "Epoch 9/10\n",
            "109242/109242 [==============================] - 6s 59us/step - loss: 0.4350 - acc: 0.8161 - val_loss: 1.1132 - val_acc: 0.6393\n",
            "Epoch 10/10\n",
            "109242/109242 [==============================] - 6s 59us/step - loss: 0.4123 - acc: 0.8268 - val_loss: 1.1699 - val_acc: 0.6370\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGgkPcSbuRwf",
        "colab_type": "code",
        "outputId": "e718ae2f-3dd4-45d9-8728-78cae98bd7e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHOHnH3Sud_a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# saving the state of the model for future use\n",
        "cnn_model.save(\"cnn_model.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSCxhMNQuiCW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model\n",
        "model = load_model('cnn_model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AiebGVx33fX5",
        "colab_type": "code",
        "outputId": "bb3d5ff0-b2cd-4297-bad0-0377ce0b121e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        }
      },
      "source": [
        "# testing the model and displaying the precision, recall and f1 score of the model\n",
        "from sklearn.metrics import classification_report\n",
        "predection=cnn_model.predict_classes(X_test,verbose=1)\n",
        "Y_test=np.argmax(Y_test, axis=1)\n",
        "print(classification_report(Y_test, predection, digits=5))"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "46818/46818 [==============================] - 2s 45us/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0    0.49406   0.31517   0.38484      2110\n",
            "           1    0.52043   0.53273   0.52651      8081\n",
            "           2    0.73085   0.76580   0.74792     23920\n",
            "           3    0.54218   0.54044   0.54131      9929\n",
            "           4    0.52211   0.42081   0.46602      2778\n",
            "\n",
            "    accuracy                        0.63700     46818\n",
            "   macro avg    0.56193   0.51499   0.53332     46818\n",
            "weighted avg    0.63146   0.63700   0.63279     46818\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KmX6-1ZB324U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}